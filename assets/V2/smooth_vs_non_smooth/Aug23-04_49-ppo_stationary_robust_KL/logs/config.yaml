!!python/object:utils.tools.dict2class
K_epochs: 10
action_dim: 2
actor_adv_step_size: 50
adv_lr: 0.002
adv_type: KL
batch_size: 2048
delta: 0.05
device: cuda
entropy_coef: 0.01
epsilon: 0.2
evaluate_freq: 1000
gamma: 0.99
hidden_width: 64
lamda: 0.95
lr_a: 0.0003
lr_c: 0.0003
max_action: 1.0
max_episode_steps: 100
max_train_steps: 5000000.0
mini_batch_size: 64
num_agents: 3
policy_dist: Gaussian
random_seed: 10
run_info: Aug23-04_49_ppo_stationary_robust_KL
run_name: ppo_stationary_robust_KL
save_freq: 20
seed: 10
set_adam_eps: true
state_dim: 10
train_adv: true
type_reward: Lagrangian
use_adv_norm: true
use_grad_clip: true
use_lr_decay: true
use_orthogonal_init: true
use_reward_norm: false
use_reward_scaling: true
use_state_norm: false
use_tanh: true
